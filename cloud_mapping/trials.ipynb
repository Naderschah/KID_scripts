{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of below migrated into cloud cover function in functions.py (same directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to iterate for a few years and see what happens\n",
    "import os\n",
    "os.chdir('/home/KID/KID_scripts/cloud_mapping/')\n",
    "from functions import cloudcover_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Querying products: 100%|██████████| 250/250 [00:01<00:00, 114.42product/s]\n",
      "Querying products: 100%|██████████| 1105/1105 [00:08<00:00, 117.42product/s]\n",
      "Querying products: 100%|██████████| 1418/1418 [00:17<00:00, 75.88product/s]\n",
      "Querying products: 100%|██████████| 1674/1674 [00:18<00:00, 87.11product/s] \n",
      "Querying products: 100%|██████████| 1897/1897 [00:19<00:00, 91.94product/s] \n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    try:\n",
    "        cloudcover_func(i*5, 2018, footprint_path='map.geojson')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     active environment : None\n",
      "       user config file : /home/jovyan/.condarc\n",
      " populated config files : /opt/conda/.condarc\n",
      "                          /home/jovyan/.condarc\n",
      "          conda version : 22.11.1\n",
      "    conda-build version : not installed\n",
      "         python version : 3.10.8.final.0\n",
      "       virtual packages : __archspec=1=x86_64\n",
      "                          __glibc=2.35=0\n",
      "                          __linux=5.15.0=0\n",
      "                          __unix=0=0\n",
      "       base environment : /opt/conda  (writable)\n",
      "      conda av data dir : /opt/conda/etc/conda\n",
      "  conda av metadata url : None\n",
      "           channel URLs : https://conda.anaconda.org/conda-forge/linux-64\n",
      "                          https://conda.anaconda.org/conda-forge/noarch\n",
      "          package cache : /opt/conda/pkgs\n",
      "                          /home/jovyan/.conda/pkgs\n",
      "       envs directories : /opt/conda/envs\n",
      "                          /home/jovyan/.conda/envs\n",
      "               platform : linux-64\n",
      "             user-agent : conda/22.11.1 requests/2.28.1 CPython/3.10.8 Linux/5.15.0-46-generic ubuntu/22.04.1 glibc/2.35\n",
      "                UID:GID : 1000:100\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info\n",
    "# To kill port in use (only do if you know its n old juyter instance)\n",
    "# fuser 8888/tcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First we need to get some lidar cloud maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/KID/KID_scripts/cloud_mapping/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "api = SentinelAPI('Naderschah', 'VuqZzLLcXEv3KS6', 'https://apihub.copernicus.eu/apihub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying products: 100%|██████████| 1419/1419 [00:28<00:00, 46.79product/s]\n"
     ]
    }
   ],
   "source": [
    "# Here we can create our footprint, to creae a file go here: https://geojsoncreator.com/\n",
    "footprint = geojson_to_wkt(read_geojson('map.geojson'))\n",
    "cloudcover_max = 15\n",
    "start_date = date(2020, 1, 1)\n",
    "\n",
    "# Now we can query (MSI 2A data product)\n",
    "products = api.query(footprint,\n",
    "                     date = ('20200101', date(2020, 12, 31)),\n",
    "                     platformname = 'Sentinel-2',\n",
    "                     cloudcoverpercentage = (0, cloudcover_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get meta data, as this contains geograpy and cloud percentages its all we actually need\n",
    "meta = api.to_geodataframe(products)\n",
    "# Only select level 2A products\n",
    "meta = meta[meta.title.apply(lambda x:x.startswith('S2B_MSIL2A'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop stuff we definetly do not need \n",
    "meta.drop(['link','link_alternative','link_icon', 'ondemand', 'vegetationpercentage', 'notvegetatedpercentage','uuid'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt \n",
    "# Format date column\n",
    "meta['Date'] = meta.summary.apply(lambda x: dt.datetime.strptime(x.split(\",\")[0].strip(\"Date: \").split('.')[0].strip(' '), \"%Y-%m-%dT%H:%M:%S\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the TileIds and geometry fields in the meta table, and the tile id kml fiel : S2A_OPER_GIP_TILPAR_MPC__20151209T095117_V20150622T000000_21000101T000000_B00.kml\n",
    "\n",
    "It is clear the the polygons in the geometry section are for some reason lon/lat instead of lat/lon so they need to be inverted\n",
    "\n",
    "This can be done with the .reverse() attribute on any shapeley loaded geometry object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot on map to see where these data products live \n",
    "\n",
    "from wktplot.plots.osm import OpenStreetMapsPlot\n",
    "from shapely.ops import transform\n",
    "import shapely\n",
    "\n",
    "plot = OpenStreetMapsPlot(\"Open Street Map Plot\", save_dir=\"cloud_free_plot\")\n",
    "\n",
    "# First we need to exchange the ordering of the polyogn coordinates\n",
    "def flip(x, y):\n",
    "    \"\"\"Flips the x and y coordinate values\"\"\"\n",
    "    return y, x\n",
    "\n",
    "# Use colorcoding to gve cloudcover probab percentage\n",
    "for idx, row in meta.iterrows():\n",
    "    # Ignore nan values for now\n",
    "    red = row.mediumprobacloudspercentage*cloudcover_max/255 //1\n",
    "    blue = row.highprobacloudspercentage*cloudcover_max/255 //1\n",
    "    #plot.add_shape(transform(flip, row.geometry), fill_color=(red, 0, 0, 0.5))\n",
    "    plot.add_shape(transform(flip, row.geometry), fill_alpha=0.25, fill_color=\"firebrick\")\n",
    "perim = transform(flip,shapely.wkt.loads(footprint))\n",
    "\n",
    "plot.add_shape(transform(flip,perim), fill_alpha=0.25, fill_color=\"blue\") \n",
    "\n",
    "# The plot can be opened in a browser or something that can read html\n",
    "plot.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too determine when all area is covered we will create a cube array that will be populated with nan values around the footprint\n",
    "# after all elements beloning to the footprint will be set to 0 and then interatively overwritten with the earliest clear observation\n",
    "# Using the first index and the last index we cna then find the minimum itme required to cover the entire surface area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get outer perimeter:\n",
    "import shapely\n",
    "perim = transform(flip,shapely.wkt.loads(footprint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "minx, miny, maxx, maxy = perim.bounds\n",
    "scaler = 50\n",
    "minx= int((minx)//1)  \n",
    "miny= int((miny)//1)  \n",
    "maxx= int((maxx)//1+1)\n",
    "maxy= int((maxy)//1+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "date_array = np.empty(shape=((maxx-minx)*scaler, scaler*(maxy-miny)),dtype='datetime64[ns]')\n",
    "date_array[:] = np.datetime64(\"NaT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from suntime import Sun\n",
    "# Really inefficient need to find a better way of doing this\n",
    "for x in range(len(date_array)):\n",
    "    for y in range(len(date_array[x])):\n",
    "        # reestablish coordinate\n",
    "        lat = y/scaler + miny\n",
    "        lon = x/scaler + minx\n",
    "        # Check if they intersect with any polygon in the geopandas array\n",
    "        bool_series = meta.geometry.contains(shapely.Point(lat,lon))\n",
    "        # Grab dates\n",
    "        # TODO: the below evaluates to nan for all where cloudcoverpercentage is not nan need to find out details before moving on\n",
    "        if len(meta[bool_series].Date.dropna())>0 : \n",
    "            # Now we check if the date is a night time or daytime obsrevation\n",
    "            sun=Sun(lat,lon)\n",
    "            # Turn the Date (type datetime) column to type date \n",
    "            dat = meta[bool_series].Date.dropna()\n",
    "            # Create second bool refering to the ordering of meta[bool_series].Date.dropna()\n",
    "            second_bool = dat.apply(lambda x: sun.get_sunset_time(x.date()).timestamp() < x.timestamp() < sun.get_sunrise_time(x.date()).timestamp())\n",
    "            # Check if something is left an move on\n",
    "            if len(meta[bool_series].Date.dropna()[second_bool])>0:\n",
    "                date_array[x,y] = meta[bool_series].Date.dropna()[second_bool].dropna().min().to_numpy().astype('datetime64[ns]')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting obs on the: 2020-01-01\n",
      "Earliest Possible: 2020-01-06\n",
      "Earliest time of full observation of footprint: 2020-05-28\n"
     ]
    }
   ],
   "source": [
    "date_range = date_array.flatten()\n",
    "date_range = date_range[~np.isnan(date_range)]\n",
    "print(\"Starting obs on the: {}\".format(start_date))\n",
    "print(\"Earliest Possible: {}\".format(np.datetime_as_string(date_range.min(), unit='D')))\n",
    "print(\"Earliest time of full observation of footprint: {}\".format(np.datetime_as_string(date_range.max(), unit='D')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-05-28'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5072ffb4707905e9ac3e5bc077411b5debabf54916eb21a5fb84af926c735de7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
